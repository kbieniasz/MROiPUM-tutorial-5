{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorytmy rozpoznawania twarzy „feature-based”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprostsze algorytmy detekcji twarzy opierają się na znajdowaniu prostych wzorców geometrycznych o wysokim kontraście (ciemne i jasne plamy). Po raz pierwszy algorytm wykorzystujący takie rozwiązanie został zaproponowany przez Paula Violę i Michaela Jonesa w 2001 roku. W literaturze bywa nazywany klasyfikatorem kaskadowym wykorzystującym cechy Haara. Viola i Jones w swojej pracy jako przykład podali następujące cechy:\n",
    "![title](images/oryginalne_cechy.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można wykorzystywać też inne proste szablony, istotna jest łatwość z jaką można je odnaleźć na obrazie.\n",
    "![title](images/Cechy_haaro-podobne.jpg)\n",
    "\n",
    "Sprawdzanie czy dany obszar posiada daną cechę jest wykonywane poprzez obliczanie różnicy sumy poziomów szarości pikselów pokrywanych przez biały oraz czarny prostokąt oraz sumy poziomów szarości pikseli pokrywanych przez czarny prostokąt.\n",
    "Ponieważ powtarzanie operacji obliczania wartości cechy haaro-podobnej przez sumowanie poziomów szarości obrazu doprowadziłoby do znacznego wydłużenia procesu detekcji Viola wprowadził pojęcie obrazu scałkowanego. \n",
    "Operacje scałkowania obrazu polega na obliczeniu funcji dwóch funkcji operujących na poziomie szarości dla współrzędnych każdego piksela, dzięki czemu suma poziomów jasności pikseli obejmujących dowolny prostokątny obszar może być obliczana w stałym czasie, ponieważ zawiera po dwie operacje dodawania oraz odejmowania.\n",
    "\n",
    "Warto zwrócić uwagę, iż tylko niektóre obliczone cechy mają znaczenie, aby wykryć twarz. Przykładowo na poniższym rysunku, największe znaczenie mają wyszczególnione cechy w okolicach nosa, oczu i ust:\n",
    "![title](images/Przyklad_wykorzystania.jpg)\n",
    "\n",
    "Ażeby wybrać najbardziej znaczące cechy wykorzystuje się algorytm Adaboost. Boosting jest meta-algorytmem opisującym sposób konstrukcji wysoce poprawnego klasyfikatora spośród słabych klasyfikatorów. Mając zdefiniowany algorytm uczenia prostych reguł klasyfikujących, algorytm boosting’u wywołuje go w serii rund, za każdym razem na innym rozkładzie wag danych uczących. W każdej rundzie wybierany jest jeden słaby klasyfikator, który lepiej klasyfikuje wcześniej błędnie sklasyfikowane dane. Wynikowy klasyfikator jest liniową kombinacją słabych klasyfikatorówo wagach przypisanych im w trakcie uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying a picture\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('images/0152.jpg')\n",
    "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example eye classifier\n",
    "eye_cascade = cv.CascadeClassifier('features/haarcascade_eye.xml')\n",
    "img = cv.imread('images/prezydent.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "face_cascade = cv.CascadeClassifier('features/haarcascade_frontalface_default.xml')\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (ex,ey,ew,eh) in eyes:\n",
    "    cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "\n",
    "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face classifier\n",
    "face_cascade = cv.CascadeClassifier('features/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv.imread('images/facerecognition2.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y,w,h) in faces:\n",
    "    img = cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\n",
    "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/malysz2.jfif')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "\n",
    "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group picture\n",
    "img = cv.imread('images/krolewska4.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\n",
    "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozpoznawanie twarzy metodą MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozpoznawanie twarzy za pomocą wielozadaniowych, kaskadowych głębokich sieci neuronowych. \n",
    "Zadanie rozpoznania twarzy odbywa się w 3 etapach, gdzie do każdego użyta jest inna sieć. Dzięki używaniu na początku słabszych a następnie coraz mocniejszych sieci można pogodzić dokładność z wydajnością. Z początku mniej dokładne sieci wyznaczają dużo potencjalnych kandydatów(okien), a następne dokładniejsze sieci skupiają się tylko na tych kandydatach, eliminując znaczną ich część, nie musząc przy tym wykonywać tak dużej ilości obliczeń, jakie musiałyby wykonać sprawdzając wszystkie możliwe okna. \n",
    "W pierwszym etapie, użyta jest prosta sieć(Proposal Network), która służy do wydajnego wyznaczenia okien-kandydatów - oraz określenia rozmiarów tych okien. Następnie za pomocą metody NMS(służącej do wykrywania krawędzi) najbardziej nachodzące na siebie okna zostają ze sobą złączone. \n",
    " \n",
    "![title](images/2_1.jpg) \n",
    "Następnie kolejna sieć(Refine Network) spośród uzyskanych wcześniej okien odrzuca znaczną część, poprzez dokładniejsze sprawdzenie okien, następnie dzięki NMS złącza się nachodzących kandydatów.  \n",
    "![title](images/2_2.jpg) \n",
    " \n",
    "Na samym końcu użyta jest najmocniejsza, podobna do poprzedniej, sieć(Output Network), która dokonuje ostatecznego wyboru, dodatkowo oznaczając 5 specyficznych elementów twarzy - nos, oczy, oraz oba kąciki ust. \n",
    "![title](images/2_3.jpg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "\n",
    "\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "#print(outp)\n",
    "color = (255, 0, 0)\n",
    "color2 = (0, 255, 0) \n",
    "radius = 3\n",
    "thickness = 5\n",
    "\n",
    "def draw(outps,img):\n",
    "    for outp in outps:\n",
    "        (x,y,w,h) = outp['box']\n",
    "        img = cv.rectangle(img, (x,y),(x+w,y+h), color, thickness)\n",
    "        for keypoint in 'left_eye','right_eye','nose','mouth_left','mouth_right': #zaznaczanie istotnych punktow twarzy\n",
    "            (x,y) = outp['keypoints'][keypoint]\n",
    "            img = cv.circle(img, (x,y), radius, color2, thickness )    \n",
    "    plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/facerecognition2.jpg\")\n",
    "outp = detector.detect_faces(img) # detekcja\n",
    "draw(outp,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img2 = cv.imread(\"images/krolewska4.jpg\")\n",
    "outp2= detector.detect_faces(img2)\n",
    "draw(outp2,img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografia:\n",
    "\n",
    "\"Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks\"\n",
    "Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, Senior Member, IEEE, and Yu Qiao, Senior Member, IEEE : \n",
    "https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf\n",
    "\n",
    "P. Viola, M. Jones, Rapid object detecTon using a boosted cascade of sample features, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and PaYern RecogniTon. CVPR 2001, Kauai, HI, USA, 2001.\n",
    "https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf\n",
    "\n",
    "http://opencvpopolsku.blogspot.com/2014/02/wykrywanie-twarzy-w-opencv.html\n",
    "\n",
    "https://www.robotyka.ia.pw.edu.pl/papers/pwilkowski-msc-09-twiki.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie\n",
    "Przetestuj zaprezentowane algorytmy na wybranym przez siebie zdjęciu. Dodatkowo sprawdź czy obie metody są tak samo skuteczne dla zdjęć, na których znajduje się wiele osób. Porównaj otrzymane rezultaty działania algorytmów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miejsce na Twój kod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
